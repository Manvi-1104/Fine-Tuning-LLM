{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4e8VQ7Tpai-",
        "outputId": "b983a667-e7f7-4c44-c54a-38c394396e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas openpyxl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the datasets using pandas library"
      ],
      "metadata": {
        "id": "n9U00BoNWGgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset=pd.read_csv('/content/Sheet 2-medsqud.csv')\n",
        "dataset1=pd.read_csv('/content/Sheet 3-medsqud.csv')\n",
        "dataset2=pd.read_csv('/content/Sheet 4-medsqud.csv')\n",
        "dataset3=pd.read_csv('/content/Sheet 5-medsqud.csv')\n",
        "dataset4=pd.read_csv('/content/Sheet 6-medsqud.csv')\n",
        "dataset5=pd.read_csv('/content/Sheet 7-medsqud.csv')\n",
        "dataset6=pd.read_csv('/content/Sheet 8-medsqud.csv')\n",
        "dataset7=pd.read_csv('/content/Sheet 9-medsqud.csv')\n",
        "print(f\"Number of rows for 2: {dataset.shape[0]}\")\n",
        "print(f\"Number of columns: {dataset.shape[1]}\")\n",
        "print(f\"Number of rows for 3: {dataset1.shape[0]}\")\n",
        "print(f\"Number of columns: {dataset1.shape[1]}\")\n",
        "print(f\"Number of rows for 4: {dataset2.shape[0]}\")\n",
        "print(f\"Number of columns: {dataset2.shape[1]}\")\n",
        "print(f\"Number of rows for 5: {dataset3.shape[0]}\")\n",
        "print(f\"Number of columns: {dataset3.shape[1]}\")\n",
        "print(f\"Number of rows for 6: {dataset4.shape[0]}\")\n",
        "print(f\"Number of columns: {dataset4.shape[1]}\")\n",
        "print(f\"Number of rows for 7: {dataset5.shape[0]}\")\n",
        "print(f\"Number of columns: {dataset5.shape[1]}\")\n",
        "print(f\"Number of rows for 8: {dataset6.shape[0]}\")\n",
        "print(f\"Number of columns: {dataset6.shape[1]}\")\n",
        "print(f\"Number of rows for 9: {dataset7.shape[0]}\")\n",
        "print(f\"Number of columns: {dataset7.shape[1]}\")\n"
      ],
      "metadata": {
        "id": "xZ_rWYtwqAEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -U accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yYaSR7v_sxiN",
        "outputId": "39709e1b-b482-4089-b15f-16cef2e9152b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, accelerate\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 transformers-4.42.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "32e2db978cb048e8b19d34a56040e01a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing the dataset which has highest number of rows for training and the lowest number of rows for validation"
      ],
      "metadata": {
        "id": "-vHbkVwbWZK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "\n",
        "# # Verify accelerate installation\n",
        "# import accelerate\n",
        "\n",
        "\n",
        "# import torch\n",
        "# from transformers import Trainer, TrainingArguments, GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n",
        "# # Check if CUDA (GPU support) is available\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print(f'Using device: {device}')\n",
        "# # Load the model and tokenizer\n",
        "# model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2').to(device)  # Load model on GPU if available\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('openai-community/gpt2')\n",
        "\n",
        "# # Prepare the dataset\n",
        "# def load_dataset(file_path, tokenizer, block_size=128):\n",
        "#     dataset = TextDataset(\n",
        "#         tokenizer=tokenizer,\n",
        "#         file_path=file_path,\n",
        "#         block_size=block_size,\n",
        "#     )\n",
        "#     return dataset\n",
        "\n",
        "# train_dataset = load_dataset(\"/content/Sheet 4-medsqud.csv\", tokenizer)\n",
        "# val_dataset = load_dataset(\"/content/Sheet 2-medsqud.csv\", tokenizer)\n",
        "\n",
        "# data_collator = DataCollatorForLanguageModeling(\n",
        "#     tokenizer=tokenizer,\n",
        "#     mlm=False,\n",
        "# )\n",
        "\n",
        "# # Set training arguments\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./results\",\n",
        "#     overwrite_output_dir=True,\n",
        "#     num_train_epochs=5,\n",
        "#     per_device_train_batch_size=8,  # Increase batch size\n",
        "#     gradient_accumulation_steps=4,   # Accumulate gradients\n",
        "#     save_steps=20_000,               # Save less frequently\n",
        "#     save_total_limit=3,              # Limit total checkpoints\n",
        "#     fp16=True                        # Enable mixed precision training\n",
        "# )\n",
        "\n",
        "# # Initialize Trainer\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     data_collator=data_collator,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=None\n",
        "# )\n",
        "\n",
        "# # Train the model\n",
        "# trainer.train()\n",
        "\n",
        "import os\n",
        "\n",
        "# Verify accelerate installation\n",
        "import accelerate\n",
        "\n",
        "import torch\n",
        "from transformers import Trainer, TrainingArguments, GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2').to(device)  # Load model on GPU if available\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('openai-community/gpt2')\n",
        "\n",
        "# Prepare the dataset\n",
        "def load_dataset(file_path, tokenizer, block_size=128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=file_path,\n",
        "        block_size=block_size,\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "train_dataset = load_dataset(\"/content/Sheet 4-medsqud.csv\", tokenizer)\n",
        "val_dataset = load_dataset(\"/content/Sheet 2-medsqud.csv\", tokenizer)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,  # Increase batch size\n",
        "    gradient_accumulation_steps=4,   # Accumulate gradients\n",
        "    save_steps=20_000,               # Save less frequently\n",
        "    save_total_limit=3,              # Limit total checkpoints\n",
        "    fp16=True,                       # Enable mixed precision training\n",
        "    evaluation_strategy=\"epoch\",     # Evaluate at the end of each epoch\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=500,               # Log every 500 steps\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,        # Add evaluation dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate(eval_dataset=val_dataset)\n",
        "print(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained(\"./fine-tuned-model\")\n",
        "tokenizer.save_pretrained(\"./fine-tuned-model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "Dz6CkMpEuhGS",
        "outputId": "d0ae6267-7f6e-43a8-e8a7-792115784df7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [510/510 05:14, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.296923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.271025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.263554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.259907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.263307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.267569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.271430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.019000</td>\n",
              "      <td>2.273418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='134' max='134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [134/134 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 2.2734177112579346, 'eval_runtime': 5.3724, 'eval_samples_per_second': 198.606, 'eval_steps_per_second': 24.942, 'epoch': 9.951219512195122}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine-tuned-model/tokenizer_config.json',\n",
              " './fine-tuned-model/special_tokens_map.json',\n",
              " './fine-tuned-model/vocab.json',\n",
              " './fine-tuned-model/merges.txt',\n",
              " './fine-tuned-model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving a test prompt to check if model is trained or not..."
      ],
      "metadata": {
        "id": "Uyq9fmUBWf2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"What is Parkinson disease\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device) # Move inputs to the same device as the model\n",
        "outputs = model.generate(**inputs)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMbdHssiwRBx",
        "outputId": "156e2609-477d-4da1-8346-874445fb6b54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is Parkinson disease,\"   Parkinson's disease is a condition that affects the brain's ability to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loss is No Log which indicates that the model shows no training loss in that many steps"
      ],
      "metadata": {
        "id": "fNG5LhOoWp2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question Answering"
      ],
      "metadata": {
        "id": "ETFermRDMl8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Verify accelerate installation\n",
        "import accelerate\n",
        "\n",
        "import torch\n",
        "from transformers import Trainer, TrainingArguments, GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2').to(device)  # Load model on GPU if available\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('openai-community/gpt2')\n",
        "\n",
        "# Check if the tokenizer has a pad_token, if not set it to eos_token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Prepare the dataset\n",
        "def load_dataset(file_path, tokenizer, block_size=128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=file_path,\n",
        "        block_size=block_size,\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "train_dataset = load_dataset(\"/content/Sheet 5-medsqud.csv\", tokenizer)\n",
        "val_dataset = load_dataset(\"/content/Sheet 6-medsqud.csv\", tokenizer)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,  # Increase batch size\n",
        "    gradient_accumulation_steps=4,   # Accumulate gradients\n",
        "    save_steps=20_000,               # Save less frequently\n",
        "    save_total_limit=3,              # Limit total checkpoints\n",
        "    fp16=True,\n",
        "    learning_rate=1e-5,# Enable mixed precision training\n",
        "    evaluation_strategy=\"epoch\",     # Evaluate at the end of each epoch\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=1000,\n",
        "    # Log every 500 steps\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,        # Add evaluation dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate(eval_dataset=val_dataset)\n",
        "print(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "# Function to generate a response given an input question\n",
        "def generate_response(question, model, tokenizer, max_length=200, num_return_sequences=1):\n",
        "    inputs = tokenizer.encode(question, return_tensors='pt').to(device)\n",
        "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=num_return_sequences, pad_token_id=tokenizer.eos_token_id)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Test the fine-tuned model\n",
        "input_text = \"What is Dementia?\"\n",
        "response = generate_response(input_text, model, tokenizer)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "jykXmcjU6K89",
        "outputId": "30abc2f6-e9f4-4d63-9374-bf631b787b76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [220/220 05:07, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.623462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.482611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.427663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.396048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.388823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.384115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.380532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.379951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 2.3799514770507812, 'eval_runtime': 10.1318, 'eval_samples_per_second': 196.708, 'eval_steps_per_second': 24.675, 'epoch': 9.67032967032967}\n",
            "What is Dementia?\n",
            "\n",
            "Dementia is a condition that affects the brain, causing changes in the way the brain functions. It can be caused by a variety of conditions, including Alzheimer's disease, Parkinson's disease, and dementia.\n",
            "\n",
            "What are the symptoms of dementia,\"Dementia is a condition that affects the brain, causing changes in the way the brain functions. It can be caused by a variety of conditions, including Alzheimer's disease, Parkinson's disease, and dementia.\"\n",
            "\n",
            "What are the symptoms of dementia,\"Dementia is a condition that affects the brain, causing changes in the way the brain functions. It can be caused by a variety of conditions, including Alzheimer's disease, Parkinson's disease, and dementia.\"\n",
            "\n",
            "What are the symptoms of dementia,\"Dementia is a condition that affects the brain, causing changes in the way the brain functions. It can be caused by a variety of conditions, including Alzheimer's disease, Parkinson's disease,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"What is cancer and what are it's symptoms?\"\n",
        "response = generate_response(input_text, model, tokenizer)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-T7TrFZ0s1q",
        "outputId": "0fbcffd5-55e1-4c18-bc4b-b2a4c328c6c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is cancer and what are it's symptoms?\n",
            "  Cancer is a serious, life-threatening condition that affects the body's immune system. It can affect the way your body functions, including your immune system, your immune system's ability to fight off infections, and your immune system's ability to fight off cancer. It can also affect your immune system's ability to fight off infections.\n",
            "  What are the symptoms of cancer,\"   The symptoms of cancer include a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high temperature, a high\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # You only need to run this once per machine\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U datasets scipy ipywidgets matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZmeJUvIzOhV",
        "outputId": "acc27549-fe58-43aa-e043-ffee1045786d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "-g2h96ANxJky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "CjaxQ2iOxTpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqvfpIYBxcXa",
        "outputId": "be2097b5-b091-4969-9521-3ff57fd238b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1632800 || all params: 126072608 || trainable%: 1.2951266939762205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "m4uk2Q2wxdAy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_checkpoints_data=json.load(open(\"/content/results/checkpoint-510/trainer_state.json\"))\n"
      ],
      "metadata": {
        "id": "mofOviRHxoO3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = []\n",
        "loss = []\n",
        "eval_loss = []\n",
        "steps=[]\n",
        "for x in train_checkpoints_data['log_history']:\n",
        "    try:\n",
        "        lr.append(x['learning_rate'])\n",
        "        loss.append(x['loss'])\n",
        "        steps.append(x['step'])\n",
        "    except:\n",
        "        eval_loss.append(x['eval_loss'])"
      ],
      "metadata": {
        "id": "3b9s9tJcxxoy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly65OVNCx0QU",
        "outputId": "6d8cccbf-1f75-4dd8-eccb-afcae400f44c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9923076923076926e-05,\n",
              " 1.9813186813186815e-05,\n",
              " 1.9703296703296705e-05,\n",
              " 1.9593406593406594e-05,\n",
              " 1.9483516483516484e-05,\n",
              " 1.9373626373626377e-05,\n",
              " 1.9263736263736266e-05,\n",
              " 1.9153846153846156e-05,\n",
              " 1.9043956043956045e-05,\n",
              " 1.8934065934065935e-05,\n",
              " 1.8824175824175824e-05,\n",
              " 1.8714285714285717e-05,\n",
              " 1.8604395604395607e-05,\n",
              " 1.8494505494505496e-05,\n",
              " 1.8384615384615386e-05,\n",
              " 1.8274725274725275e-05,\n",
              " 1.8164835164835165e-05,\n",
              " 1.8054945054945057e-05,\n",
              " 1.7945054945054947e-05,\n",
              " 1.7835164835164836e-05,\n",
              " 1.7725274725274726e-05,\n",
              " 1.7615384615384615e-05,\n",
              " 1.7505494505494508e-05,\n",
              " 1.7395604395604398e-05,\n",
              " 1.7285714285714287e-05,\n",
              " 1.7175824175824177e-05,\n",
              " 1.7065934065934066e-05,\n",
              " 1.6956043956043956e-05,\n",
              " 1.684615384615385e-05,\n",
              " 1.6736263736263738e-05,\n",
              " 1.6626373626373628e-05,\n",
              " 1.6516483516483517e-05,\n",
              " 1.6406593406593406e-05,\n",
              " 1.62967032967033e-05,\n",
              " 1.618681318681319e-05,\n",
              " 1.607692307692308e-05,\n",
              " 1.5967032967032968e-05,\n",
              " 1.5857142857142857e-05,\n",
              " 1.5747252747252747e-05,\n",
              " 1.563736263736264e-05,\n",
              " 1.552747252747253e-05,\n",
              " 1.541758241758242e-05,\n",
              " 1.5307692307692308e-05,\n",
              " 1.5197802197802198e-05,\n",
              " 1.5087912087912089e-05,\n",
              " 1.497802197802198e-05,\n",
              " 1.486813186813187e-05,\n",
              " 1.475824175824176e-05,\n",
              " 1.4648351648351648e-05,\n",
              " 1.453846153846154e-05,\n",
              " 1.4428571428571429e-05,\n",
              " 1.431868131868132e-05,\n",
              " 1.420879120879121e-05,\n",
              " 1.4098901098901101e-05,\n",
              " 1.3989010989010989e-05,\n",
              " 1.387912087912088e-05,\n",
              " 1.3769230769230771e-05,\n",
              " 1.365934065934066e-05,\n",
              " 1.3549450549450552e-05,\n",
              " 1.3439560439560441e-05,\n",
              " 1.332967032967033e-05,\n",
              " 1.321978021978022e-05,\n",
              " 1.3109890109890111e-05,\n",
              " 1.3000000000000001e-05,\n",
              " 1.2890109890109892e-05,\n",
              " 1.278021978021978e-05,\n",
              " 1.2670329670329671e-05,\n",
              " 1.256043956043956e-05,\n",
              " 1.2450549450549452e-05,\n",
              " 1.2340659340659343e-05,\n",
              " 1.2230769230769232e-05,\n",
              " 1.212087912087912e-05,\n",
              " 1.2010989010989011e-05,\n",
              " 1.1901098901098903e-05,\n",
              " 1.1791208791208792e-05,\n",
              " 1.1681318681318683e-05,\n",
              " 1.1571428571428573e-05,\n",
              " 1.1461538461538462e-05,\n",
              " 1.1351648351648352e-05,\n",
              " 1.1241758241758243e-05,\n",
              " 1.1131868131868134e-05,\n",
              " 1.1021978021978024e-05,\n",
              " 1.0912087912087911e-05,\n",
              " 1.0802197802197802e-05,\n",
              " 1.0692307692307694e-05,\n",
              " 1.0582417582417583e-05,\n",
              " 1.0472527472527474e-05,\n",
              " 1.0362637362637364e-05,\n",
              " 1.0252747252747253e-05,\n",
              " 1.0142857142857143e-05,\n",
              " 1.0032967032967034e-05,\n",
              " 9.923076923076923e-06,\n",
              " 9.813186813186813e-06,\n",
              " 9.703296703296704e-06,\n",
              " 9.593406593406595e-06,\n",
              " 9.483516483516483e-06,\n",
              " 9.373626373626374e-06,\n",
              " 9.263736263736265e-06,\n",
              " 9.153846153846155e-06,\n",
              " 9.043956043956044e-06,\n",
              " 8.934065934065936e-06,\n",
              " 8.824175824175825e-06,\n",
              " 8.714285714285715e-06,\n",
              " 8.604395604395606e-06,\n",
              " 8.494505494505495e-06,\n",
              " 8.384615384615385e-06,\n",
              " 8.274725274725274e-06,\n",
              " 8.164835164835165e-06,\n",
              " 8.054945054945057e-06,\n",
              " 7.945054945054946e-06,\n",
              " 7.835164835164836e-06,\n",
              " 7.725274725274727e-06,\n",
              " 7.615384615384615e-06,\n",
              " 7.505494505494506e-06,\n",
              " 7.395604395604397e-06,\n",
              " 7.285714285714286e-06,\n",
              " 7.175824175824177e-06,\n",
              " 7.065934065934067e-06,\n",
              " 6.9560439560439565e-06,\n",
              " 6.846153846153847e-06,\n",
              " 6.736263736263737e-06,\n",
              " 6.626373626373627e-06,\n",
              " 6.516483516483517e-06,\n",
              " 6.406593406593407e-06,\n",
              " 6.296703296703297e-06,\n",
              " 6.186813186813187e-06,\n",
              " 6.076923076923077e-06,\n",
              " 5.967032967032967e-06,\n",
              " 5.857142857142858e-06,\n",
              " 5.747252747252748e-06,\n",
              " 5.637362637362638e-06,\n",
              " 5.527472527472528e-06,\n",
              " 5.417582417582418e-06,\n",
              " 5.307692307692308e-06,\n",
              " 5.1978021978021985e-06,\n",
              " 5.087912087912088e-06,\n",
              " 4.978021978021978e-06,\n",
              " 4.868131868131869e-06,\n",
              " 4.758241758241758e-06,\n",
              " 4.6483516483516485e-06,\n",
              " 4.538461538461539e-06,\n",
              " 4.428571428571429e-06,\n",
              " 4.3186813186813195e-06,\n",
              " 4.208791208791209e-06,\n",
              " 4.098901098901099e-06,\n",
              " 3.98901098901099e-06,\n",
              " 3.87912087912088e-06,\n",
              " 3.7692307692307694e-06,\n",
              " 3.6593406593406593e-06,\n",
              " 3.54945054945055e-06,\n",
              " 3.43956043956044e-06,\n",
              " 3.32967032967033e-06,\n",
              " 3.2197802197802203e-06,\n",
              " 3.10989010989011e-06,\n",
              " 3e-06,\n",
              " 2.89010989010989e-06,\n",
              " 2.7802197802197807e-06,\n",
              " 2.6703296703296707e-06,\n",
              " 2.5604395604395606e-06,\n",
              " 2.4505494505494505e-06,\n",
              " 2.340659340659341e-06,\n",
              " 2.230769230769231e-06,\n",
              " 2.120879120879121e-06,\n",
              " 2.0109890109890114e-06,\n",
              " 1.901098901098901e-06,\n",
              " 1.7912087912087914e-06,\n",
              " 1.6813186813186815e-06,\n",
              " 1.5714285714285714e-06,\n",
              " 1.4615384615384618e-06,\n",
              " 1.3516483516483517e-06,\n",
              " 1.2417582417582418e-06,\n",
              " 1.131868131868132e-06,\n",
              " 1.021978021978022e-06,\n",
              " 9.120879120879121e-07,\n",
              " 8.021978021978023e-07,\n",
              " 6.923076923076924e-07,\n",
              " 5.824175824175824e-07,\n",
              " 4.7252747252747256e-07,\n",
              " 3.626373626373627e-07,\n",
              " 2.5274725274725275e-07,\n",
              " 1.4285714285714287e-07,\n",
              " 3.296703296703297e-08]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_checkpoints_data=json.load(open(\"/content/results/checkpoint-510/trainer_state.json\"))\n",
        "\n",
        "lr = []\n",
        "loss = []\n",
        "eval_loss = []\n",
        "steps=[]\n",
        "for x in train_checkpoints_data['log_history']:\n",
        "    lr.append(x.get('learning_rate', None))  # Use get() with a default value to handle missing keys\n",
        "    loss.append(x.get('loss', None))\n",
        "    eval_loss.append(x.get('eval_loss', None))  # Append to eval_loss even if 'eval_loss' key is missing\n",
        "    steps.append(x.get('step', None))\n",
        "\n",
        "# Remove None values from the lists to ensure they have the same length\n",
        "steps = [s for s in steps if s is not None]\n",
        "loss = [l for l in loss if l is not None]\n",
        "eval_loss = [e for e in eval_loss if e is not None]\n",
        "\n",
        "# Ensure that 'steps', 'loss', and 'eval_loss' have the same length before plotting\n",
        "min_length = min(len(steps), len(loss), len(eval_loss))\n",
        "steps = steps[:min_length]\n",
        "loss = loss[:min_length]\n",
        "eval_loss = eval_loss[:min_length]  # Trim eval_loss to match the length\n",
        "\n",
        "plt.plot(steps, loss, label=\"Train loss\")\n",
        "plt.plot(steps, eval_loss, label= \"Eval loss\")\n",
        "leg= plt.legend()\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A_bPuDhz9sUz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "fdf6b39d-031a-413b-edf9-490fdfe93789"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNRVulOcXB-9",
        "outputId": "05720c5c-5791-41f5-d1a0-1f741ae6291e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki4fAnQ2bV2x",
        "outputId": "842eb57d-6829-438e-a978-0483aff0cb1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.37.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.2 (from gradio)\n",
            "  Downloading gradio_client-1.0.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.2->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.2->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=9b5a630eae628ebc23dac8b7f8d0e4f807e254c22df9f774c746fb19c70ea0da\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.37.2 gradio-client-1.0.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.5 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.5.0 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = 'openai-community/gpt2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Check if the tokenizer has a pad_token, if not set it to eos_token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Function to generate a response given an input question\n",
        "def generate_response(question):\n",
        "    inputs = tokenizer.encode(question, return_tensors='pt')\n",
        "    outputs = model.generate(inputs, max_length=50, pad_token_id=tokenizer.eos_token_id)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Define the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"GPT-2 Medical Question Answering\",\n",
        "    description=\"Ask a question and get a response from a fine-tuned GPT-2 model.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "rscxbYoHbcwU",
        "outputId": "901a25f2-c51d-43c6-ffd9-4848cd733b30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://72122bb625facd94ad.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://72122bb625facd94ad.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}